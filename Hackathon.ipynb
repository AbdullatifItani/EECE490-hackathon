{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Abdullah Itani\n",
        "Abdullatif Itani"
      ],
      "metadata": {
        "id": "LjZEhDx9Hf-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Given the data in the excel, we wanted to try and predict the starting age for smoking depending on some of the given variables namely:\n",
        "I see myself as someone who is extraverted, enthusiastic:\tI see myself as someone who is critical, quarrelsome:\tI see myself as someone who is dependable, self-disciplined:\tI see myself as someone who is anxious, easily upset:\tI see myself as someone who is open to new experiences:\tI see myself as someone who is reserved, quiet:\tI see myself as someone who is sympathetic, warm:\tI see myself as someone who is disorganized, careless:\tI see myself as someone who is calm, emotionally stable:\tI see myself as someone who is conventional, uncreative:"
      ],
      "metadata": {
        "id": "rInNs58HzJgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are columns 3-12 included, result is on 19 (age) we decided to use Random Forest\n"
      ],
      "metadata": {
        "id": "xgvv3nknz6P5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0gU3CY23VGG",
        "outputId": "708b2f86-a1d2-464f-f135-0f5d06213e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFxr7Y6nzJDd",
        "outputId": "b022499c-456e-478f-fcb8-73bacae2e4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-c503af5eca05>:21: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  features = features.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
            "<ipython-input-26-c503af5eca05>:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  features = features.replace(likert_mapping)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation Metrics:\n",
            "Mean Absolute Error (MAE): 21.27\n",
            "Mean Squared Error (MSE): 12055.67\n",
            "R^2 Score: -1002.46\n"
          ]
        }
      ],
      "source": [
        "def build_model(file_path):\n",
        "    # Load the dataset from the provided Excel file\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Select columns 3-12 as features (assuming 0-based indexing)\n",
        "    features = df.iloc[:, 4:14]  # Changed from 4:13 to 3:13\n",
        "    target = df.iloc[:, 20]      # Column 21 (age of first cigarette)\n",
        "\n",
        "    # Define the mapping for Likert scale responses\n",
        "    likert_mapping = {\n",
        "        'Disagree strongly': 1,\n",
        "        'Disagree moderately': 2,\n",
        "        'Disagree a little': 3,\n",
        "        'Neither agree nor disagree': 4,\n",
        "        'Agree a little': 5,\n",
        "        'Agree moderately': 6,\n",
        "        'Agree strongly': 7\n",
        "    }\n",
        "\n",
        "    # Clean the features: strip whitespace, standardize text, and apply mapping\n",
        "    features = features.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "    features = features.replace(likert_mapping)\n",
        "\n",
        "    # Handle missing values by filling with the median of each column\n",
        "    features.fillna(features.median(), inplace=True)\n",
        "\n",
        "    # Check for any remaining non-numeric values\n",
        "    if features.isnull().values.any():\n",
        "        print(\"Warning: There are still unmapped or invalid values in the features.\")\n",
        "        print(features[features.isnull().any(axis=1)])\n",
        "        return\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target,\n",
        "                                                        test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize a Random Forest Regressor\n",
        "    model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(\"Model Evaluation Metrics:\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"R^2 Score: {r2:.2f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'  # Replace with the actual file path\n",
        "\n",
        "# Build and train the model\n",
        "if __name__ == \"__main__\":\n",
        "    model = build_model(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'  # Update file path\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Select features and target\n",
        "features = df.iloc[:, 4:14]  # Columns 5-13 (Likert-scale personality traits)\n",
        "target = df.iloc[:, 20]      # Column 21 (Age first cigarette)\n",
        "\n",
        "# Map Likert responses to numerical values\n",
        "likert_mapping = {\n",
        "    'Disagree strongly': 1,\n",
        "    'Disagree moderately': 2,\n",
        "    'Disagree a little': 3,\n",
        "    'Neither agree nor disagree': 4,\n",
        "    'Agree a little': 5,\n",
        "    'Agree moderately': 6,\n",
        "    'Agree strongly': 7\n",
        "}\n",
        "\n",
        "# Apply mapping and handle missing data\n",
        "features = features.replace(likert_mapping)\n",
        "features.fillna(features.median(), inplace=True)\n",
        "\n",
        "# Check correlation with the target variable\n",
        "correlation = features.corrwith(target)\n",
        "print(\"Correlation with Target (Sorted):\")\n",
        "print(correlation.sort_values())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz1aM8sh4-fr",
        "outputId": "4a3e746e-083b-4e7f-ff49-2175d478bc67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation with Target (Sorted):\n",
            "I see myself as someone who is anxious, easily upset:          -0.131818\n",
            "I see myself as someone who is disorganized, careless:         -0.094892\n",
            "I see myself as someone who is conventional, uncreative:       -0.073528\n",
            "I see myself as someone who is critical, quarrelsome:          -0.017418\n",
            "I see myself as someone who is extraverted, enthusiastic:       0.032044\n",
            "I see myself as someone who is open to new experiences:         0.064728\n",
            "I see myself as someone who is dependable, self-disciplined:    0.071184\n",
            "I see myself as someone who is sympathetic, warm:               0.084954\n",
            "I see myself as someone who is calm, emotionally stable:        0.100191\n",
            "I see myself as someone who is reserved, quiet:                 0.125105\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-828c032a2097>:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  features = features.replace(likert_mapping)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation Metrics:\n",
        "*   Mean Absolute Error (MAE): 21.27\n",
        "*   Mean Squared Error (MSE): 12055.67\n",
        "*   R^2 Score: -1002.46\n",
        "\n",
        "Our metrics are very bad so lets try to use less features that correlate more with the result"
      ],
      "metadata": {
        "id": "qsmKLU3B7s_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def build_model(file_path):\n",
        "    # Load the dataset from the provided Excel file\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Select columns 12, 10, and 9 as features (assuming 0-based indexing)\n",
        "    features = df.iloc[:, [12, 10, 9]]  # Use specific columns as features\n",
        "    target = df.iloc[:, 20]             # Column 21 (age of first cigarette)\n",
        "\n",
        "    # Define the mapping for Likert scale responses\n",
        "    likert_mapping = {\n",
        "        'Disagree strongly': 1,\n",
        "        'Disagree moderately': 2,\n",
        "        'Disagree a little': 3,\n",
        "        'Neither agree nor disagree': 4,\n",
        "        'Agree a little': 5,\n",
        "        'Agree moderately': 6,\n",
        "        'Agree strongly': 7\n",
        "    }\n",
        "\n",
        "    # Apply mapping and handle missing values\n",
        "    features = features.replace(likert_mapping)\n",
        "    features.fillna(features.median(), inplace=True)\n",
        "\n",
        "    # Check for any remaining non-numeric values\n",
        "    if features.isnull().values.any():\n",
        "        print(\"Warning: There are still unmapped or invalid values in the features.\")\n",
        "        print(features[features.isnull().any(axis=1)])\n",
        "        return\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target,\n",
        "                                                        test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize a Random Forest Regressor\n",
        "    model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(\"Model Evaluation Metrics:\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"R^2 Score: {r2:.2f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'  # Replace with the actual file path\n",
        "\n",
        "# Build and train the model\n",
        "if __name__ == \"__main__\":\n",
        "    model = build_model(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qew4tOru7vld",
        "outputId": "aef0a592-f508-4f58-f6e4-af23a0547170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation Metrics:\n",
            "Mean Absolute Error (MAE): 10.92\n",
            "Mean Squared Error (MSE): 2640.79\n",
            "R^2 Score: -218.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-14c6c3281de8>:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  features = features.replace(likert_mapping)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'  # Update file path\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Select columns 12, 10, 9 as features and column 21 as the target\n",
        "features = df.iloc[:, [12, 10, 9]]\n",
        "target = df.iloc[:, 20]  # Column 21 (age of first cigarette)\n",
        "\n",
        "# Define the mapping for Likert scale responses\n",
        "likert_mapping = {\n",
        "    'Disagree strongly': 1,\n",
        "    'Disagree moderately': 2,\n",
        "    'Disagree a little': 3,\n",
        "    'Neither agree nor disagree': 4,\n",
        "    'Agree a little': 5,\n",
        "    'Agree moderately': 6,\n",
        "    'Agree strongly': 7\n",
        "}\n",
        "\n",
        "# Map Likert responses to numerical values\n",
        "features = features.replace(likert_mapping)\n",
        "\n",
        "# Handle missing values\n",
        "features.fillna(features.median(), inplace=True)\n",
        "\n",
        "# Compute correlations with the target variable\n",
        "correlation = features.corrwith(target)\n",
        "print(\"Correlation with Target (Sorted):\")\n",
        "print(correlation.sort_values())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x0udUd39WxX",
        "outputId": "b492e890-b834-4e82-f33d-77025cc1fa59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation with Target (Sorted):\n",
            "I see myself as someone who is sympathetic, warm:           0.084954\n",
            "I see myself as someone who is calm, emotionally stable:    0.100191\n",
            "I see myself as someone who is reserved, quiet:             0.125105\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-17f637d482c2>:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  features = features.replace(likert_mapping)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Again we have horrendous results\n",
        "Model Evaluation Metrics:\n",
        "*   Mean Absolute Error (MAE): 10.92\n",
        "*   Mean Squared Error (MSE): 2640.79\n",
        "*   R^2 Score: -218.81\n",
        "\n",
        "Looking through the data we saw that there was an outlier age of 2016 and 189, and the min max of the data was 13, 24. Hence we decided to make the model only consider ages below 30, and make a prediction between ages 10-30"
      ],
      "metadata": {
        "id": "I4oZUz9L99DM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def build_model(file_path):\n",
        "    # Load the dataset from the provided Excel file\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Select columns 12, 10, and 9 as features (assuming 0-based indexing)\n",
        "    features = df.iloc[:, [12, 10, 9]]  # Use specific columns as features\n",
        "    target = df.iloc[:, 20]             # Column 21 (age of first cigarette)\n",
        "\n",
        "    # Remove rows where the target age is above 30\n",
        "    valid_indices = target <= 30\n",
        "    features = features[valid_indices]\n",
        "    target = target[valid_indices]\n",
        "\n",
        "    # Define the mapping for Likert scale responses\n",
        "    likert_mapping = {\n",
        "        'Disagree strongly': 1,\n",
        "        'Disagree moderately': 2,\n",
        "        'Disagree a little': 3,\n",
        "        'Neither agree nor disagree': 4,\n",
        "        'Agree a little': 5,\n",
        "        'Agree moderately': 6,\n",
        "        'Agree strongly': 7\n",
        "    }\n",
        "\n",
        "    # Apply mapping and handle missing values\n",
        "    features = features.replace(likert_mapping)\n",
        "    features.fillna(features.median(), inplace=True)\n",
        "\n",
        "    # Check for any remaining non-numeric values\n",
        "    if features.isnull().values.any():\n",
        "        print(\"Warning: There are still unmapped or invalid values in the features.\")\n",
        "        print(features[features.isnull().any(axis=1)])\n",
        "        return\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target,\n",
        "                                                        test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize a Random Forest Regressor\n",
        "    model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Constrain predictions to the range [10, 30]\n",
        "    y_pred = y_pred.clip(10, 30)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(\"Model Evaluation Metrics:\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"R^2 Score: {r2:.2f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'  # Replace with the actual file path\n",
        "\n",
        "# Build and train the model\n",
        "if __name__ == \"__main__\":\n",
        "    model = build_model(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P47oYDip9-kI",
        "outputId": "2051a7d6-a633-41d8-d269-4e546e9d478b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-0f2fd291bb36>:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  features = features.replace(likert_mapping)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation Metrics:\n",
            "Mean Absolute Error (MAE): 2.03\n",
            "Mean Squared Error (MSE): 7.45\n",
            "R^2 Score: 0.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion we managed to improve our predictions as much as possible but in the end we can deduce that the given variables aren't very suitable to predict the age a person smoked a full cigarette, so lets try something else!"
      ],
      "metadata": {
        "id": "hXtNXxdV_DWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second Idea\n",
        "As we was browsing through the data we were interested in the subject of cigarette brands however the data is way to jumbled to get an accurate prediction on what cigarette brand someone is using, so we decided to see if someone can afford his favorite cigarette brand."
      ],
      "metadata": {
        "id": "yanjtjY8COyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Affording favorite cigarette brand\n",
        "The data I will use here and might change later on are: Employment status(47 AV), How often do you feel stressed?(46 AU), To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?(43 AR), How would you describe your current income sufficiency?(41 AP), What is the highest level of education you have attained?(29 AD)"
      ],
      "metadata": {
        "id": "TFxLrgoZDC0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
        "\n",
        "def logistic_regression_model(file_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Select features and target\n",
        "    features = df[[\n",
        "        \"Employment Status\",\n",
        "        \"How often do you feel stressed?\",\n",
        "        \"To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?\",\n",
        "        \"How would you describe your current income sufficiency?\",\n",
        "        \"What is the highest level of education you have attained?\"\n",
        "    ]]\n",
        "    target = df.iloc[:, 24]  # Column 24: Can afford favorite cigarette brand?\n",
        "\n",
        "    # Encode categorical variables\n",
        "    categorical_features = features.select_dtypes(include=['object']).columns\n",
        "    features = pd.get_dummies(features, columns=categorical_features, drop_first=True)  # One-hot encoding for categorical variables\n",
        "\n",
        "    # Encode the target variable (1 for Yes, 0 for No)\n",
        "    target = target.map({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "    # Handle missing values\n",
        "    features.fillna(features.median(), inplace=True)\n",
        "    target.dropna(inplace=True)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize the Logistic Regression model\n",
        "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]  # Probability of class 1 (Yes)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    print(\"Logistic Regression Model Evaluation:\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'  # Replace with your file path\n",
        "\n",
        "# Build and train the model\n",
        "if __name__ == \"__main__\":\n",
        "    model = logistic_regression_model(file_path)\n"
      ],
      "metadata": {
        "id": "9lIctpWB_KPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad51224-e237-40cf-ab0a-7037d7b25407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Evaluation:\n",
            "Accuracy: 0.67\n",
            "Precision: 0.74\n",
            "Recall: 0.83\n",
            "F1 Score: 0.78\n",
            "ROC-AUC Score: 0.69\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.31      0.36        13\n",
            "           1       0.74      0.83      0.78        30\n",
            "\n",
            "    accuracy                           0.67        43\n",
            "   macro avg       0.59      0.57      0.57        43\n",
            "weighted avg       0.65      0.67      0.65        43\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We tried using Logistic regression but the results weren't very accurate, and the predictions of \"Yes\" were more accurate than \"No\" due to the imbalance in the data set, lets try random forest"
      ],
      "metadata": {
        "id": "W4spatJ_MxGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
        "\n",
        "def random_forest_model(file_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Select features and target\n",
        "    features = df[[\n",
        "        \"Employment Status\",\n",
        "        \"How often do you feel stressed?\",\n",
        "        \"To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?\",\n",
        "        \"How would you describe your current income sufficiency?\",\n",
        "        \"What is the highest level of education you have attained?\"\n",
        "    ]]\n",
        "    target = df.iloc[:, 24]  # Column 24: Can afford favorite cigarette brand?\n",
        "\n",
        "    # Encode categorical variables\n",
        "    categorical_features = features.select_dtypes(include=['object']).columns\n",
        "    features = pd.get_dummies(features, columns=categorical_features, drop_first=True)  # One-hot encoding for categorical variables\n",
        "\n",
        "    # Encode the target variable (1 for Yes, 0 for No)\n",
        "    target = target.map({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "    # Handle missing values\n",
        "    features.fillna(features.median(), inplace=True)\n",
        "    target.dropna(inplace=True)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize the Random Forest Classifier\n",
        "    model = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]  # Probability of class 1 (Yes)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    print(\"Random Forest Model Evaluation:\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'  # Replace with your file path\n",
        "\n",
        "# Build and train the model\n",
        "if __name__ == \"__main__\":\n",
        "    model = random_forest_model(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGIEL8gONOjh",
        "outputId": "d0393d96-12d6-49a9-b1ed-432dfe4c1a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Evaluation:\n",
            "Accuracy: 0.70\n",
            "Precision: 0.81\n",
            "Recall: 0.73\n",
            "F1 Score: 0.77\n",
            "ROC-AUC Score: 0.77\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.62      0.55        13\n",
            "           1       0.81      0.73      0.77        30\n",
            "\n",
            "    accuracy                           0.70        43\n",
            "   macro avg       0.66      0.67      0.66        43\n",
            "weighted avg       0.72      0.70      0.71        43\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def feature_correlation_analysis(file_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Select features and target\n",
        "    features = df[[\n",
        "        \"Employment Status\",\n",
        "        \"How often do you feel stressed?\",\n",
        "        \"To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?\",\n",
        "        \"How would you describe your current income sufficiency?\",\n",
        "        \"What is the highest level of education you have attained?\"\n",
        "    ]]\n",
        "    target = df.iloc[:, 24]  # Column 24: Can afford favorite cigarette brand?\n",
        "\n",
        "    # Encode categorical variables\n",
        "    categorical_features = features.select_dtypes(include=['object']).columns\n",
        "    features = pd.get_dummies(features, columns=categorical_features, drop_first=True)\n",
        "\n",
        "    # Encode the target variable (1 for Yes, 0 for No)\n",
        "    target = target.map({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "    # Handle missing values\n",
        "    features.fillna(features.median(), inplace=True)\n",
        "    target.dropna(inplace=True)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize and train Random Forest\n",
        "    model = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Feature importance\n",
        "    feature_importances = pd.DataFrame({\n",
        "        'Feature': features.columns,\n",
        "        'Importance': model.feature_importances_\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    print(\"Feature Importance (Correlation Proxy):\")\n",
        "    print(feature_importances)\n",
        "\n",
        "    return feature_importances\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'  # Replace with your file path\n",
        "\n",
        "# Analyze feature importance and correlation\n",
        "if __name__ == \"__main__\":\n",
        "    feature_importances = feature_correlation_analysis(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ3CC4t1Ox4W",
        "outputId": "ddeefeef-c413-42cf-e40b-b1091808af9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance (Correlation Proxy):\n",
            "                                              Feature  Importance\n",
            "9   How would you describe your current income suf...    0.143980\n",
            "7   To what extent were you financially (negativel...    0.108091\n",
            "0                        Employment Status_Unemployed    0.079406\n",
            "1          How often do you feel stressed?_Frequently    0.074936\n",
            "8   To what extent were you financially (negativel...    0.073031\n",
            "10  How would you describe your current income suf...    0.069336\n",
            "13  What is the highest level of education you hav...    0.061584\n",
            "3        How often do you feel stressed?_Occasionally    0.059492\n",
            "5   To what extent were you financially (negativel...    0.058659\n",
            "6   To what extent were you financially (negativel...    0.048909\n",
            "11  How would you describe your current income suf...    0.038403\n",
            "15  What is the highest level of education you hav...    0.038019\n",
            "4              How often do you feel stressed?_Rarely    0.035720\n",
            "14  What is the highest level of education you hav...    0.034477\n",
            "16  What is the highest level of education you hav...    0.030330\n",
            "12  How would you describe your current income suf...    0.028796\n",
            "17  What is the highest level of education you hav...    0.009221\n",
            "18  What is the highest level of education you hav...    0.005750\n",
            "2               How often do you feel stressed?_Never    0.001861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the results were sub-optimal we decided to do a weighted model based on the features importance"
      ],
      "metadata": {
        "id": "9Bi7u1xsPbAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
        "\n",
        "def weighted_random_forest_model(file_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Select features and target\n",
        "    features = df[[\n",
        "        \"Employment Status\",\n",
        "        \"How often do you feel stressed?\",\n",
        "        \"To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?\",\n",
        "        \"How would you describe your current income sufficiency?\",\n",
        "        \"What is the highest level of education you have attained?\"\n",
        "    ]]\n",
        "    target = df.iloc[:, 24]  # Column 24: Can afford favorite cigarette brand?\n",
        "\n",
        "    # Encode categorical variables\n",
        "    categorical_features = features.select_dtypes(include=['object']).columns\n",
        "    features = pd.get_dummies(features, columns=categorical_features, drop_first=True)\n",
        "\n",
        "    # Encode the target variable (1 for Yes, 0 for No)\n",
        "    target = target.map({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "    # Handle missing values\n",
        "    features.fillna(features.median(), inplace=True)\n",
        "    target.dropna(inplace=True)\n",
        "\n",
        "    # Calculate feature importances using an initial Random Forest\n",
        "    temp_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100)\n",
        "    temp_model.fit(features, target)\n",
        "    importances = temp_model.feature_importances_\n",
        "\n",
        "    # Scale each feature by its importance\n",
        "    weighted_features = features * importances\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(weighted_features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize and train the final Random Forest\n",
        "    model = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]  # Probability of class 1 (Yes)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    print(\"Weighted Random Forest Model Evaluation:\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'  # Replace with your file path\n",
        "\n",
        "# Build and train the model\n",
        "if __name__ == \"__main__\":\n",
        "    model = weighted_random_forest_model(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONlQKA5PP0aL",
        "outputId": "bdca6f90-702b-4ca8-c500-6ecc7c728f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Random Forest Model Evaluation:\n",
            "Accuracy: 0.70\n",
            "Precision: 0.81\n",
            "Recall: 0.73\n",
            "F1 Score: 0.77\n",
            "ROC-AUC Score: 0.77\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.62      0.55        13\n",
            "           1       0.81      0.73      0.77        30\n",
            "\n",
            "    accuracy                           0.70        43\n",
            "   macro avg       0.66      0.67      0.66        43\n",
            "weighted avg       0.72      0.70      0.71        43\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results were sub-optimal so we decided to try a different model XGBoost"
      ],
      "metadata": {
        "id": "XUvzriNIQwLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
        "\n",
        "def xgboost_model(file_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Select features and target\n",
        "    features = df[[\n",
        "        \"Employment Status\",\n",
        "        \"How often do you feel stressed?\",\n",
        "        \"To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?\",\n",
        "        \"How would you describe your current income sufficiency?\",\n",
        "        \"What is the highest level of education you have attained?\"\n",
        "    ]]\n",
        "    target = df.iloc[:, 24]  # Column 24: Can afford favorite cigarette brand?\n",
        "\n",
        "    # Encode categorical variables\n",
        "    categorical_features = features.select_dtypes(include=['object']).columns\n",
        "    features = pd.get_dummies(features, columns=categorical_features, drop_first=True)\n",
        "\n",
        "    # Encode the target variable (1 for Yes, 0 for No)\n",
        "    target = target.map({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "    # Handle missing values\n",
        "    features.fillna(features.median(), inplace=True)\n",
        "    target.dropna(inplace=True)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize and train XGBoost Classifier\n",
        "    model = XGBClassifier(\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,  # Suppresses a warning for older XGBoost versions\n",
        "        eval_metric=\"logloss\",  # Metric to evaluate\n",
        "        scale_pos_weight=1.5,   # Adjust for class imbalance (tune this value as needed)\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=3\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]  # Probability of class 1 (Yes)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    print(\"XGBoost Model Evaluation:\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'  # Replace with your file path\n",
        "\n",
        "# Build and train the model\n",
        "if __name__ == \"__main__\":\n",
        "    model = xgboost_model(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1PxAlwzQx97",
        "outputId": "b597215c-82a0-4190-d83f-ed78ba13206e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model Evaluation:\n",
            "Accuracy: 0.67\n",
            "Precision: 0.75\n",
            "Recall: 0.80\n",
            "F1 Score: 0.77\n",
            "ROC-AUC Score: 0.70\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.38      0.42        13\n",
            "           1       0.75      0.80      0.77        30\n",
            "\n",
            "    accuracy                           0.67        43\n",
            "   macro avg       0.60      0.59      0.60        43\n",
            "weighted avg       0.66      0.67      0.67        43\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [08:38:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results were similar but a bit better note that we refrained from using the feature in col 25 as there is a direct correlation between it and col 24"
      ],
      "metadata": {
        "id": "t2mTOoOIQy-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How many cigarettes do you smoke each day?\n",
        "\n",
        "We'll use the following features to predict it:\n",
        "\n",
        "Selected Features\n",
        "*   \"Gender:\"\n",
        "*   \"How old are you?\"\n",
        "*   \"What is your current employment status?\"\n",
        "*   \"How often do you feel stressed?\"\n",
        "*   \"How would you describe your current income sufficiency"
      ],
      "metadata": {
        "id": "kO9GgFG1TEup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def logistic_regression_model(file_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Define target and features\n",
        "    target_column = 'How many cigarettes do you smoke each day?'  # Replace with exact target column\n",
        "    feature_columns = [\n",
        "        'Gender:',\n",
        "        'How old are you?',\n",
        "        'What is your current employment status?',\n",
        "        'How often do you feel stressed?',\n",
        "        'How would you describe your current income sufficiency?'\n",
        "    ]\n",
        "\n",
        "    # Select features and target\n",
        "    features = df[feature_columns]\n",
        "    target = df[target_column]\n",
        "\n",
        "    # Drop rows with missing target values\n",
        "    valid_indices = target.dropna().index\n",
        "    target = target.loc[valid_indices]\n",
        "    features = features.loc[valid_indices]\n",
        "\n",
        "    # Preprocess target: Encode categorical target variable\n",
        "    le_target = LabelEncoder()\n",
        "    target = le_target.fit_transform(target)\n",
        "\n",
        "    # Preprocess features: Handle missing values and encode categorical data\n",
        "    features = features.fillna('Unknown')  # Fill missing values with a placeholder\n",
        "    features = pd.get_dummies(features, drop_first=True)  # One-hot encoding for categorical features\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train Logistic Regression\n",
        "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Logistic Regression Model Evaluation:\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return model, le_target\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'\n",
        "logistic_model, label_encoder = logistic_regression_model(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8ZvyA7nYi_I",
        "outputId": "0f3b4224-68af-4d2b-8174-b7ed2f0fc020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Evaluation:\n",
            "Accuracy: 0.47\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.62      0.54        16\n",
            "           1       0.47      0.67      0.55        12\n",
            "           2       1.00      0.18      0.31        11\n",
            "           3       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.47        43\n",
            "   macro avg       0.49      0.37      0.35        43\n",
            "weighted avg       0.56      0.47      0.43        43\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "def xgboost_model_with_limitation(file_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Define target and features\n",
        "    target_column = 'How many cigarettes do you smoke each day?'  # Replace with exact target column\n",
        "    feature_columns = [\n",
        "        'Gender:',\n",
        "        'How old are you?',\n",
        "        'What is your current employment status?',\n",
        "        'How often do you feel stressed?',\n",
        "        'How would you describe your current income sufficiency?'\n",
        "    ]\n",
        "\n",
        "    # Select features and target\n",
        "    features = df[feature_columns]\n",
        "    target = df[target_column]\n",
        "\n",
        "    # Drop rows with missing target values\n",
        "    valid_indices = target.dropna().index\n",
        "    target = target.loc[valid_indices]\n",
        "    features = features.loc[valid_indices]\n",
        "\n",
        "    # Encode target\n",
        "    le_target = LabelEncoder()\n",
        "    target_encoded = le_target.fit_transform(target)\n",
        "\n",
        "    # Preprocess features: Handle missing values and encode categorical data\n",
        "    features = features.fillna('Unknown')  # Fill missing values with a placeholder\n",
        "    features = pd.get_dummies(features, drop_first=True)  # One-hot encoding for categorical features\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Address class imbalance using SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Train an XGBoost Classifier\n",
        "    model = XGBClassifier(\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,  # Suppresses warning\n",
        "        eval_metric=\"mlogloss\",  # Multi-class evaluation metric\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=3\n",
        "    )\n",
        "    model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "    # Predict on test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Limit predictions to range 1-40 (if applicable)\n",
        "    y_pred_limited = [min(max(pred, 1), 40) for pred in y_pred]\n",
        "\n",
        "    # Decode predictions back to original labels\n",
        "    y_pred_decoded = le_target.inverse_transform(y_pred_limited)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"XGBoost Model Evaluation:\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'\n",
        "xgb_model = xgboost_model_with_limitation(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCIoC-kwZbN4",
        "outputId": "b2eaa922-9dc4-474e-838b-aa3b3a656470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model Evaluation:\n",
            "Accuracy: 0.42\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.44      0.44        16\n",
            "           1       0.45      0.42      0.43        12\n",
            "           2       0.40      0.36      0.38        11\n",
            "           3       0.33      0.50      0.40         4\n",
            "\n",
            "    accuracy                           0.42        43\n",
            "   macro avg       0.41      0.43      0.41        43\n",
            "weighted avg       0.42      0.42      0.42        43\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:14:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results to predict cigarette frequency were pretty difficult to predict even after using a different model and limiting the number of ciggs smoked this may be due to the skewed dataset and the features we chose\n",
        "# Lets now try predicting stress levels using other features!"
      ],
      "metadata": {
        "id": "FvNFxNLfaNAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def predict_stress_frequency(file_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Define target and features\n",
        "    target_column = 'How often do you feel stressed?'  # Replace with exact target column\n",
        "    feature_columns = [\n",
        "        'Gender:',\n",
        "        'How old are you?',\n",
        "        'What is your current employment status?',\n",
        "        'How would you describe your current income sufficiency?',\n",
        "        'To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?'\n",
        "    ]\n",
        "\n",
        "    # Select features and target\n",
        "    features = df[feature_columns]\n",
        "    target = df[target_column]\n",
        "\n",
        "    # Drop rows with missing target values\n",
        "    valid_indices = target.dropna().index\n",
        "    target = target.loc[valid_indices]\n",
        "    features = features.loc[valid_indices]\n",
        "\n",
        "    # Encode target\n",
        "    le_target = LabelEncoder()\n",
        "    target_encoded = le_target.fit_transform(target)\n",
        "\n",
        "    # Debug: Print classes in the LabelEncoder\n",
        "    print(\"Classes in LabelEncoder:\", le_target.classes_)\n",
        "\n",
        "    # Preprocess features: Handle missing values and encode categorical data\n",
        "    features = features.fillna('Unknown')  # Fill missing values with a placeholder\n",
        "    features = pd.get_dummies(features, drop_first=True)  # One-hot encoding for categorical features\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Debug: Print unique classes in train and test sets\n",
        "    print(\"Unique classes in training set:\", set(y_train))\n",
        "    print(\"Unique classes in test set:\", set(y_test))\n",
        "\n",
        "    # Train Logistic Regression\n",
        "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Logistic Regression Model Evaluation:\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, labels=list(set(y_test)), target_names=le_target.classes_))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'\n",
        "stress_model = predict_stress_frequency(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyyWnR-oaPgN",
        "outputId": "4ce3a443-83b1-4432-e1aa-a3e91956d2be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes in LabelEncoder: ['Constantly' 'Frequently' 'Never' 'Occasionally' 'Rarely']\n",
            "Unique classes in training set: {0, 1, 2, 3, 4}\n",
            "Unique classes in test set: {0, 1, 3, 4}\n",
            "Logistic Regression Model Evaluation:\n",
            "Accuracy: 0.35\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Constantly       0.00      0.00      0.00         3\n",
            "  Frequently       0.50      0.50      0.50        22\n",
            "       Never       0.30      0.25      0.27        12\n",
            "Occasionally       0.14      0.17      0.15         6\n",
            "\n",
            "    accuracy                           0.35        43\n",
            "   macro avg       0.24      0.23      0.23        43\n",
            "weighted avg       0.36      0.35      0.35        43\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:2642: UserWarning: labels size, 4, does not match size of target_names, 5\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not good results lets try a different model\n"
      ],
      "metadata": {
        "id": "KclWnJ3caqQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "def predict_stress_frequency_with_smote(file_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Define target and features\n",
        "    target_column = 'How often do you feel stressed?'  # Replace with exact target column\n",
        "    feature_columns = [\n",
        "        'Gender:',\n",
        "        'How old are you?',\n",
        "        'What is your current employment status?',\n",
        "        'How would you describe your current income sufficiency?',\n",
        "        'To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?'\n",
        "    ]\n",
        "\n",
        "    # Select features and target\n",
        "    features = df[feature_columns]\n",
        "    target = df[target_column]\n",
        "\n",
        "    # Drop rows with missing target values\n",
        "    valid_indices = target.dropna().index\n",
        "    target = target.loc[valid_indices]\n",
        "    features = features.loc[valid_indices]\n",
        "\n",
        "    # Combine 'Rarely' and 'Never' classes\n",
        "    target = target.replace({'Rarely': 'Rarely/Never', 'Never': 'Rarely/Never'})\n",
        "\n",
        "    # Encode target\n",
        "    le_target = LabelEncoder()\n",
        "    target_encoded = le_target.fit_transform(target)\n",
        "\n",
        "    # Preprocess features: Handle missing values and encode categorical data\n",
        "    features = features.fillna('Unknown')  # Fill missing values with a placeholder\n",
        "    features = pd.get_dummies(features, drop_first=True)  # One-hot encoding for categorical features\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Address class imbalance using SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Train Random Forest Classifier\n",
        "    model = RandomForestClassifier(random_state=42, n_estimators=100, class_weight=None)\n",
        "    model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "    # Predict on test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Decode predictions back to original labels\n",
        "    y_pred_decoded = le_target.inverse_transform(y_pred)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Random Forest Model with SMOTE Evaluation:\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=le_target.classes_))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'\n",
        "rf_smote_model = predict_stress_frequency_with_smote(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NC92e03aqlm",
        "outputId": "27c2d727-9978-4226-bf61-755a98c5cb13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model with SMOTE Evaluation:\n",
            "Accuracy: 0.40\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Constantly       0.25      0.67      0.36         3\n",
            "  Frequently       0.53      0.45      0.49        22\n",
            "Occasionally       0.36      0.33      0.35        12\n",
            "Rarely/Never       0.20      0.17      0.18         6\n",
            "\n",
            "    accuracy                           0.40        43\n",
            "   macro avg       0.33      0.41      0.35        43\n",
            "weighted avg       0.42      0.40      0.40        43\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "better but still bad lets try random forest"
      ],
      "metadata": {
        "id": "1h9rgXkcbcmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def predict_stress_frequency_with_rf(file_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Define target and features\n",
        "    target_column = 'How often do you feel stressed?'  # Replace with exact target column\n",
        "    feature_columns = [\n",
        "        'Gender:',\n",
        "        'How old are you?',\n",
        "        'What is your current employment status?',\n",
        "        'How would you describe your current income sufficiency?',\n",
        "        'To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?'\n",
        "    ]\n",
        "\n",
        "    # Select features and target\n",
        "    features = df[feature_columns]\n",
        "    target = df[target_column]\n",
        "\n",
        "    # Drop rows with missing target values\n",
        "    valid_indices = target.dropna().index\n",
        "    target = target.loc[valid_indices]\n",
        "    features = features.loc[valid_indices]\n",
        "\n",
        "    # Encode target\n",
        "    le_target = LabelEncoder()\n",
        "    target_encoded = le_target.fit_transform(target)\n",
        "\n",
        "    # Preprocess features: Handle missing values and encode categorical data\n",
        "    features = features.fillna('Unknown')  # Fill missing values with a placeholder\n",
        "    features = pd.get_dummies(features, drop_first=True)  # One-hot encoding for categorical features\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train Random Forest Classifier\n",
        "    model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Decode predictions back to original labels\n",
        "    y_pred_decoded = le_target.inverse_transform(y_pred)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Random Forest Model Evaluation:\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=le_target.classes_))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/sample_data/2024_PersonalityTraits_SurveyData.xlsx'\n",
        "rf_model = predict_stress_frequency_with_rf(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmXeNjX0bc4O",
        "outputId": "c8262063-20db-4d73-9808-87e559b5d3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Evaluation:\n",
            "Accuracy: 0.47\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Constantly       0.50      0.67      0.57         3\n",
            "  Frequently       0.57      0.59      0.58        22\n",
            "       Never       0.00      0.00      0.00         0\n",
            "Occasionally       0.38      0.42      0.40        12\n",
            "      Rarely       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.47        43\n",
            "   macro avg       0.29      0.33      0.31        43\n",
            "weighted avg       0.43      0.47      0.45        43\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best so far and we tried to tweak it a bit by  changing weights, features etc. but the accuracy never surpassed 0.55 this may be due to skewed data which is normal in real world data and improper features."
      ],
      "metadata": {
        "id": "4gjQYyO8d6Zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is the end of the predictions we tried, note that we used random forest a lot since its the most accurate in these scenarios.\n",
        "\n",
        "# Thank you!\n"
      ],
      "metadata": {
        "id": "gw9LYAM6eQkO"
      }
    }
  ]
}